data management and web scraping
========================================================
author: katie leap and stephen lauer
date: 7/19/16

Sponsors
========================================================
[![Graduate Women In STEM](gwis-logo.png)](http://blogs.umass.edu/gwis/)

[![Graduate Researchers in Data](grid-logo.png)](http://gridclub.io/)

[Western Mass Statistics and Data Science Meetup](http://www.meetup.com/Pioneer-Valley-and-Five-College-R-Statistical-Meetup/)

Data Extraction
========================================================
- With R, this isn't really a thing
- `read.csv` will read in csv files
  - very easy syntax, used most frequently
- In this workshop, we'll cover two other methods
  - Importing SAS files
  - Scraping HTML tables from the internet

Data Management
========================================================
- Actually refers to a lot of things
  - some of them very technical with names like "data architecture"
- We're using it just to refer to managing **data quality**
  - cleaning 
  - processing
- Additionally, sometimes data comes to you as a giant file, but you don't need all of it
  - R makes it easy to filter and select just the data you're interested in

Case Study 1: NHANES
========================================================
- We'll get started with a public health dataset that we're going to find online right now
- http://wwwn.cdc.gov/Nchs/Nhanes/Search/Nhanes13_14.aspx

```{r, message=FALSE, results='hide'}
library(Hmisc)
demographics <- sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT")
taste.smell <- sasxport.get("http://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/CSX_H.XPT")
```

Clean Up, Clean Up, Everybody Everywhere...
========================================================
1. Decide which variables to use
2. Look for missing data: why are they missing and is this a problem?
3. Look for out-of-range data: why would a living person have a pulse of 0 bpm?
4. Make sure numbers are numbers and factors are factors

Introducing dplyr!
========================================================
- `dplyr` works like magic
- We're going to look at the following functions in `dplyr`:
  - `select()`
  - `rename()`
  - `filter()`
  - `mutate()`
  - `group_by()`
  - `summarize()`
  - `arrange()`
- They all do what it sounds like they do

But First!
========================================================

- the pipe!
- **%>%**
- this handy little thing comes from the `magrittr` package
- it makes code a million times more readable
- keyboard shortcut: **cmd-shift-M** (for **m**agrittr)

%>% in action!
========================================================
```{r}
library(magrittr) # or dplyr

## confusing ##
mean(seq_len(sum(seq(1:10))))

## clear ##
seq(1:10) %>% 
  sum %>%
  seq_len %>% 
  mean
```

Back to NHANES
========================================================
- Our first step is to decide which variables we want to use
- We probably want to investigate a relationship, so we should choose a predictor variable and a response variable
- Now we look at the codebook to figure out what these have been named

Back to NHANES
========================================================
- Let's select the variables we decided to work with
- We can rename them at the same time
```{r}
library(plyr)
library(dplyr)
demo <- demographics %>% 
  select(id=seqn,gender=riagendr,age=ridageyr) 
```
- If we didn't want to select only a specific number of columns, we would use `rename()`

Freebie: helper functions
========================================================
- `contains()`
- `ends_with()`
- `everything()`
- `matches()`
- `num_range("x", 1:5)`: columns named x1, x2, x3, x4, x5.
- `one_of()`
- `starts_with()`

Back to Cleaning!
========================================================
- `summary()` provides summary statistics
- this is a one-stop-shop for missing data, out-of-range data and checking that numbers are numbers and factors are factors
- however magic `dplyr` is, data management relies on your brain
  - be thorough
  - document what you do
  - justify every decision you make
  - don't overwrite your original data

========================================================
<center><img src="http://imgs.xkcd.com/comics/genetic_testing.png"/></center> 

Mutants!
========================================================
- `mutate()` allows us to add new columns
- usually we do this because we have changed something about another column and want to preserve both
- for example, changing kg to lbs because this is AMERICA
- `mutate_each()`: multiple columns

Mutants!
========================================================
```{r}
demo <- demographics %>% 
  select(id=seqn,gender=riagendr,age=ridageyr) %>% 
  mutate(gender=revalue(as.factor(gender), c("1"="male","2"="female")))
summary(demo)
```


Select : Columns :: Filter : Rows
========================================================
- `filter()` allows you to pick rows that have a specific value inside a column
- For example, let's say we want to pick all of the women
```{r}
women <- demo %>% 
  filter(gender=="female")
```
- You can use the >, <, ==, >=, and <= operators to `filter()` rows
```{r}
old.farts <- demo %>% 
  filter(age>75)
```

Summarize
========================================================
- When we want to get one number, we use `summarize()`
- Think of functions like `mean()`
```{r}
demo %>% 
  summarize(mean.age = mean(age))
```
- `summarize_each()`: multiple columns


Grouping
========================================================
```{r}
group <- demo %>%
  group_by(gender)
head(group)
```

Arrange
========================================================
```{r}
arrange <- demo %>% 
  arrange(gender)
head(arrange)
```


Divide and Conquer!
========================================================
```{r}
demo %>%
  group_by(gender) %>%  
  summarize(mean.age = mean(age))
```


Freebie: Summarize function examples
========================================================
- `dplyr` specific:
  - `first`: First value of a vector.
  - `last`: Last value of a vector.
  - `nth`: Nth value of a vector.
  - `n`: # of values in a vector.
  - `n_distinct`: # of distinct values in a vector.
- Other functions:
  - `IQR`
  - `min`, `max`
  - `mean`, `median`
  - `var`, `sd`

Why did we download two datasets?
========================================================
- Because we can join them!
- There are different joins depending on how you want to do it
- I look them up every time: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf

But first!
========================================================
- 10 minutes to clean the second dataset!
- Remember to:
  - select just the variables you want (rename probably)
  - look for missing values
  - check your factors

```{r, echo=FALSE}
ts <- taste.smell %>% 
  select(id=seqn,runny=csq260n,choc=csxchood) %>% 
  mutate(runny=replace(runny,is.na(runny),0) %>% 
           as.factor %>% 
           revalue(c("1"="yes","0"="no")),
         choc=revalue(as.factor(choc),c("1"="Lemon", "2"="Chocolate", 
                                        "3"="Smoke","4"="Black pepper")))
```

Left join!
========================================================
```{r}
full.dat <- left_join(demo, ts, by = "id") # or your df name
```
- Optional `by` statement
- Can use more than one `by` variables as well
  - `by = c("id","age")`

Have fun!
========================================================
- Find some interesting stuff, please
- Take a snack break if you like
- Let us know what you find!
  - Do old people smell funny?
- Complete list of dplyr functions can be found on the [`dplyr` cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

Web Scraping
========================================================
- Refers to extracting information from websites
- Really easy to do in R with the help of some packages
  - `XML`
  - `rvest`

Case Study 2: NBA
========================================================
```{r}
library(XML)
site <- "http://www.basketball-reference.com/teams/BOS/2016.html"
celtics_2016 <- readHTMLTable(site)
celtics_players <- celtics_2016$per_game
```

Case Study 2: NBA
========================================================
```{r, echo=F}
celtics_players %>% 
  select(Player, Age, G, PTS) %>% 
  head
```

Case Study 2: NBA
========================================================
```{r, warnings=FALSE}
years <- 1980:2013
all_celtics <- c()
for(year in years){
  site <- paste0("http://www.basketball-reference.com/teams/BOS/", year, ".html")
  celtics_one_year <- readHTMLTable(site)
  one_year_players <- celtics_one_year$per_game
  one_year_players$Year <- year
  all_celtics <- bind_rows(all_celtics, one_year_players)
}
```

Case Study 2: NBA
========================================================
```{r,eval=FALSE}
all_celtics %>% 
  select(Player, Year, PTS) %>% 
  arrange(desc(as.numeric(PTS)))
```

Case Study 2: NBA
========================================================
```{r,echo=FALSE}
all_celtics %>% 
  select(Player, Year, PTS) %>% 
  arrange(desc(as.numeric(PTS)))
```

Case Study 2: NBA
========================================================
```{r,eval=FALSE}
all_celtics %>% 
  group_by(Player) %>% 
  summarize(Games=sum(as.numeric(G)),             
            PPG=weighted.mean(as.numeric(PTS), as.numeric(G))) %>% 
  arrange(desc(PPG))
```

Case Study 2: NBA
========================================================
```{r,echo=FALSE}
all_celtics %>% 
  group_by(Player) %>% 
  summarize(Games=sum(as.numeric(G)),             
            PPG=weighted.mean(as.numeric(PTS), as.numeric(G))) %>% 
  arrange(desc(PPG))
```

`rvest` and the SelectorGadget
========================================================
- Load up `rvest`
```{r}
library(rvest)
```
- Download the selector gadget at [selectorgadget.com](http://selectorgadget.com/)

IMDB Web Scrape
========================================================
[IMDB's Top 100 "Robot Movies"](http://www.imdb.com/search/title?count=100&keywords=robot&num_votes=3000,&title_type=feature&ref_=gnr_kw_ro)
```{r}
imdb <- read_html("http://www.imdb.com/search/title?count=100&keywords=robot&num_votes=3000,&title_type=feature&ref_=gnr_kw_ro")

descriptions <- imdb %>% 
  html_nodes(".outline") %>% 
  html_text()
```
IMDB Web Scrape
========================================================
```{r}
descriptions[[1]]
```

IMDB Web Scrape
========================================================
```{r}
rating <- imdb %>% 
  html_nodes(".value") %>% 
  html_text() %>% 
  as.numeric
```

IMDB Web Scrape
========================================================
```{r}
head(rating)
```

IMDB Web Scrape
========================================================
```{r}
year <- imdb %>% 
  html_nodes(".year_type") %>% 
  html_text() %>% 
  gsub(pattern="\\(",replacement="") %>% 
  gsub(pattern="\\)",replacement="") %>% 
  as.numeric
```

IMDB Web Scrape
========================================================
```{r}
head(year)
```

IMDB Web Scrape
========================================================
```{r}
title <- imdb %>% 
  html_nodes(".title") %>% 
  html_text()

title2 <- unlist(strsplit(title,"\n    \n\n\n\n    "))[seq(from=2,to=length(title),by=2)]
title3 <- unlist(strsplit(title2,"\n    \\("))[seq(from=1,to=length(title),by=2)]
```

IMDB Web Scrape
========================================================
```{r}
head(title3)
```

IMDB Web Scrape
========================================================
```{r}
robot.movies <- data.frame(title=title3,year,rating)
head(arrange(robot.movies,desc(rating)),4)
```

IMDB Web Scrape Activities
========================================================
- Find which years have had the most "robot movies"
- Use `grep` to find which descriptions contain robot words ("robot", "android", "AI", etc.) to filter out fake robot movies (X-Men Apocalyse, really?)
- Find average rating of robot movies, as well as the lowest and highest rated ones

Thank You!
========================================================
[![Graduate Women In STEM](gwis-logo.png)](http://blogs.umass.edu/gwis/)

[![Graduate Researchers in Data](grid-logo.png)](http://gridclub.io/)

[Western Mass Statistics and Data Science Meetup](http://www.meetup.com/Pioneer-Valley-and-Five-College-R-Statistical-Meetup/)
